{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea8b7ed",
   "metadata": {},
   "source": [
    "# Active Learning for Text Classification using Small-Text\n",
    "## 01 - Introduction\n",
    "\n",
    "This tutorial shows how to use [small-text](https://github.com/webis-de/small-text) to perform active learning for text classification using state-of-the-art transformer models.\n",
    "\n",
    "\n",
    "### Installation\n",
    "\n",
    "Besides small-text, we also install [datasets](https://github.com/huggingface/datasets) to load an example dataset and [matptlotlib](https://matplotlib.org/) to plot the learning curves at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837556c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: small-text[transformers]==1.0.0b3 in /home/smaghino/.local/lib/python3.8/site-packages (1.0.0b3)\n",
      "Requirement already satisfied: tqdm in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (4.64.0)\n",
      "Requirement already satisfied: scipy in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (1.22.3)\n",
      "Requirement already satisfied: dill in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (0.3.4)\n",
      "Requirement already satisfied: torch>=1.6.0; extra == \"transformers\" in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (1.8.1)\n",
      "Requirement already satisfied: torchtext>=0.7.0; extra == \"transformers\" in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (0.9.1)\n",
      "Requirement already satisfied: transformers>=4.0.0; extra == \"transformers\" in /home/smaghino/.local/lib/python3.8/site-packages (from small-text[transformers]==1.0.0b3) (4.18.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/smaghino/.local/lib/python3.8/site-packages (from scikit-learn>=0.24.1->small-text[transformers]==1.0.0b3) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/smaghino/.local/lib/python3.8/site-packages (from scikit-learn>=0.24.1->small-text[transformers]==1.0.0b3) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/smaghino/.local/lib/python3.8/site-packages (from torch>=1.6.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (4.2.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchtext>=0.7.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (2.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/smaghino/.local/lib/python3.8/site-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (2022.4.24)\n",
      "Requirement already satisfied: sacremoses in /home/smaghino/.local/lib/python3.8/site-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (0.0.53)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/smaghino/.local/lib/python3.8/site-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/smaghino/.local/lib/python3.8/site-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (0.5.1)\n",
      "Requirement already satisfied: filelock in /home/smaghino/.local/lib/python3.8/site-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/smaghino/.local/lib/python3.8/site-packages (from transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (0.12.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from sacremoses->transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (7.0)\n",
      "Requirement already satisfied: six in /home/smaghino/.local/lib/python3.8/site-packages (from sacremoses->transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/smaghino/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers>=4.0.0; extra == \"transformers\"->small-text[transformers]==1.0.0b3) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /home/smaghino/.local/lib/python3.8/site-packages (2.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/smaghino/.local/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: seaborn in /home/smaghino/.local/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (1.22.3)\n",
      "Requirement already satisfied: xxhash in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: pandas in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: packaging in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (2022.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (0.5.1)\n",
      "Requirement already satisfied: dill in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in /home/smaghino/.local/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/smaghino/.local/lib/python3.8/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/smaghino/.local/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/smaghino/.local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/smaghino/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/smaghino/.local/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/smaghino/.local/lib/python3.8/site-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/smaghino/.local/lib/python3.8/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /home/smaghino/.local/lib/python3.8/site-packages (from responses<0.19->datasets) (1.26.9)\n",
      "Requirement already satisfied: filelock in /home/smaghino/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/smaghino/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/smaghino/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/smaghino/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/smaghino/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/smaghino/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/smaghino/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/smaghino/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/smaghino/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install small-text[transformers]==1.0.0b3  # use \"small-text\" without \"[transformers]\" if you want to work on the CPU only\n",
    "\n",
    "# additional dependencies for this example\n",
    "%pip install datasets matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cddec",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "Here we configure the loggging and display progress bars display of the `datasets` library to improve its appearance in the notebook. You can skip this when reading for the first time if you are only interested in active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13170d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "# disables the progress bar for notebooks: https://github.com/huggingface/datasets/issues/2651\n",
    "datasets.logging.get_verbosity = lambda: logging.NOTSET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35a787",
   "metadata": {},
   "source": [
    "Moreover, we update the default matplotlib settings to receive a more visually appealing plot at the end of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269ce876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.update({'xtick.labelsize': 14, 'ytick.labelsize': 14, 'axes.labelsize': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d6d3f",
   "metadata": {},
   "source": [
    "Finally, we will fix the random seeds so that readers do not get confused when the results change upon repeated execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7be9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "seed = 2022\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5fd19",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "First we load rotten tomatoes dataset. This dataset contains movie reviews sentences, which are labeled by their sentiment as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754e5b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d667cd331d464268821c522e549765eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training samples:\n",
      "\n",
      "1   the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "1   the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "1   effective but too-tepid biopic\n",
      "1   if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "1   emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "1   the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "1   offers that rare combination of entertainment and education .\n",
      "1   perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "1   steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "1   take care of my cat offers a refreshingly different slice of asian cinema .\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "raw_dataset = datasets.load_dataset('rotten_tomatoes')\n",
    "num_classes = np.unique(raw_dataset['train']['label']).shape[0]\n",
    "\n",
    "print('First 10 training samples:\\n')\n",
    "for i in range(10):\n",
    "    print(raw_dataset['train']['label'][i], ' ', raw_dataset['train']['text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742f7d7",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "\n",
    "Next, we have to convert this raw text data into a format usable by small-text. Since the transformer-based classification in small-text uses huggingface transformers this step is pretty similar to the preprocessing you may know from transformers, with the addition that the end result must be a `TransformersDataset`. In this example, we use `bert-base-uncased` as transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c52f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \n",
    "    transformer_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252a546",
   "metadata": {},
   "source": [
    "We define a small helper function `get_transformers_dataset()` with delegates to `tokenizer.encode_plus()` and finally builds a `TransformersDataset` instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be151ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from small_text.integrations.transformers.datasets import TransformersDataset\n",
    "\n",
    "\n",
    "def get_transformers_dataset(tokenizer, data, labels, max_length=60):\n",
    "\n",
    "    data_out = []\n",
    "\n",
    "    for i, doc in enumerate(data):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            doc,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation='longest_first'\n",
    "        )\n",
    "\n",
    "        data_out.append((encoded_dict['input_ids'], encoded_dict['attention_mask'], labels[i]))\n",
    "\n",
    "    return TransformersDataset(data_out)\n",
    "\n",
    "\n",
    "train = get_transformers_dataset(tokenizer, raw_dataset['train']['text'], raw_dataset['train']['label'])\n",
    "test = get_transformers_dataset(tokenizer, raw_dataset['test']['text'], raw_dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ebf3d",
   "metadata": {},
   "source": [
    "### Setting up the Active Learner\n",
    "\n",
    "Now we constrauct a `PoolBasedActiveLearner` instance which requires a classifier factory, a query strategy, and the train dataset.\n",
    "\n",
    "To obtain a first model, we initialize the active learner by providing the true labels for 10 sentences. This corresponds to an initial labeling the real-world setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66774521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood_err: \n",
      "tensor([[0.3920],\n",
      "        [0.6404],\n",
      "        [0.3854],\n",
      "        [0.5957],\n",
      "        [0.4557],\n",
      "        [0.5929],\n",
      "        [0.6681],\n",
      "        [0.6287],\n",
      "        [0.6044],\n",
      "        [0.6492],\n",
      "        [0.6367],\n",
      "        [0.3358],\n",
      "        [0.3496],\n",
      "        [0.3695],\n",
      "        [0.3554],\n",
      "        [0.3413],\n",
      "        [0.2737],\n",
      "        [0.6625]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1514],\n",
      "        [0.1412],\n",
      "        [0.1503],\n",
      "        [0.1549],\n",
      "        [0.1612],\n",
      "        [0.1552],\n",
      "        [0.1448],\n",
      "        [0.1504],\n",
      "        [0.1537],\n",
      "        [0.1401],\n",
      "        [0.1493],\n",
      "        [0.1406],\n",
      "        [0.1434],\n",
      "        [0.1473],\n",
      "        [0.1446],\n",
      "        [0.1418],\n",
      "        [0.1259],\n",
      "        [0.1456]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0514],\n",
      "        [0.0000],\n",
      "        [0.0159],\n",
      "        [0.0000],\n",
      "        [0.0150],\n",
      "        [0.0446],\n",
      "        [0.0275],\n",
      "        [0.0187],\n",
      "        [0.0556],\n",
      "        [0.0307],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0420]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.4119],\n",
      "        [0.6969]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1548],\n",
      "        [0.1406]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0593]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.7021, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5748],\n",
      "        [0.4157],\n",
      "        [0.3593],\n",
      "        [0.6148],\n",
      "        [0.4403],\n",
      "        [0.3761],\n",
      "        [0.3359],\n",
      "        [0.4019],\n",
      "        [0.3545],\n",
      "        [0.4476],\n",
      "        [0.5897],\n",
      "        [0.3086],\n",
      "        [0.5000],\n",
      "        [0.5400],\n",
      "        [0.4051],\n",
      "        [0.4651],\n",
      "        [0.5684],\n",
      "        [0.3791]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1576],\n",
      "        [0.1545],\n",
      "        [0.1454],\n",
      "        [0.1523],\n",
      "        [0.1550],\n",
      "        [0.1486],\n",
      "        [0.1406],\n",
      "        [0.1531],\n",
      "        [0.1341],\n",
      "        [0.1500],\n",
      "        [0.1557],\n",
      "        [0.1345],\n",
      "        [0.1667],\n",
      "        [0.1620],\n",
      "        [0.1536],\n",
      "        [0.1577],\n",
      "        [0.1584],\n",
      "        [0.1491]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[9.9726e-03],\n",
      "        [2.9171e-05],\n",
      "        [0.0000e+00],\n",
      "        [2.2261e-02],\n",
      "        [7.1258e-04],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [5.2475e-03],\n",
      "        [4.3622e-03],\n",
      "        [1.4033e-02],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [3.0081e-03],\n",
      "        [0.0000e+00],\n",
      "        [9.4473e-04],\n",
      "        [8.4157e-03],\n",
      "        [0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.4534],\n",
      "        [0.6511]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1592],\n",
      "        [0.1442]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.0001],\n",
      "        [0.0444]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.7151, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.6183],\n",
      "        [0.1765],\n",
      "        [0.4765],\n",
      "        [0.3429],\n",
      "        [0.2542],\n",
      "        [0.2854],\n",
      "        [0.4809],\n",
      "        [0.3107],\n",
      "        [0.4348],\n",
      "        [0.3033],\n",
      "        [0.5173],\n",
      "        [0.3837],\n",
      "        [0.6449],\n",
      "        [0.3217],\n",
      "        [0.3102],\n",
      "        [0.5924],\n",
      "        [0.4635],\n",
      "        [0.4348]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1518],\n",
      "        [0.0957],\n",
      "        [0.1399],\n",
      "        [0.1421],\n",
      "        [0.1206],\n",
      "        [0.1289],\n",
      "        [0.1644],\n",
      "        [0.1350],\n",
      "        [0.1450],\n",
      "        [0.1333],\n",
      "        [0.1520],\n",
      "        [0.1500],\n",
      "        [0.1481],\n",
      "        [0.1375],\n",
      "        [0.1349],\n",
      "        [0.1553],\n",
      "        [0.1392],\n",
      "        [0.1583]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0235],\n",
      "        [0.0000],\n",
      "        [0.0239],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0076],\n",
      "        [0.0000],\n",
      "        [0.0109],\n",
      "        [0.0000],\n",
      "        [0.0341],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0149],\n",
      "        [0.0225],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.5568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5652],\n",
      "        [0.5865]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1546],\n",
      "        [0.1428]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.0131],\n",
      "        [0.0392]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.7507, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5932],\n",
      "        [0.3561],\n",
      "        [0.4361],\n",
      "        [0.2668],\n",
      "        [0.2277],\n",
      "        [0.1801],\n",
      "        [0.4294],\n",
      "        [0.6143],\n",
      "        [0.4811],\n",
      "        [0.4618],\n",
      "        [0.3069],\n",
      "        [0.3508],\n",
      "        [0.6732],\n",
      "        [0.2035],\n",
      "        [0.1960],\n",
      "        [0.3328],\n",
      "        [0.5230],\n",
      "        [0.2256]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1428],\n",
      "        [0.1448],\n",
      "        [0.1430],\n",
      "        [0.1241],\n",
      "        [0.1128],\n",
      "        [0.0970],\n",
      "        [0.1575],\n",
      "        [0.1405],\n",
      "        [0.1426],\n",
      "        [0.1605],\n",
      "        [0.1341],\n",
      "        [0.1437],\n",
      "        [0.1440],\n",
      "        [0.1051],\n",
      "        [0.1026],\n",
      "        [0.1400],\n",
      "        [0.1634],\n",
      "        [0.1122]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0402],\n",
      "        [0.0000],\n",
      "        [0.0103],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0498],\n",
      "        [0.0198],\n",
      "        [0.0001],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0471],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0013],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.5243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5935],\n",
      "        [0.6172]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1509],\n",
      "        [0.1404]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.0224],\n",
      "        [0.0504]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.7874, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.6748],\n",
      "        [0.3541],\n",
      "        [0.2753],\n",
      "        [0.1846],\n",
      "        [0.3295],\n",
      "        [0.5117],\n",
      "        [0.5156],\n",
      "        [0.3670],\n",
      "        [0.3354],\n",
      "        [0.4063],\n",
      "        [0.4092],\n",
      "        [0.2037],\n",
      "        [0.1801],\n",
      "        [0.3393],\n",
      "        [0.2406],\n",
      "        [0.4362],\n",
      "        [0.4408],\n",
      "        [0.1998]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1438],\n",
      "        [0.1444],\n",
      "        [0.1263],\n",
      "        [0.0986],\n",
      "        [0.1392],\n",
      "        [0.1530],\n",
      "        [0.1608],\n",
      "        [0.1442],\n",
      "        [0.1405],\n",
      "        [0.1538],\n",
      "        [0.1480],\n",
      "        [0.1051],\n",
      "        [0.0970],\n",
      "        [0.1413],\n",
      "        [0.1167],\n",
      "        [0.1381],\n",
      "        [0.1591],\n",
      "        [0.1038]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0479],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0090],\n",
      "        [0.0023],\n",
      "        [0.0003],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0018],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0180],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.4948],\n",
      "        [0.7349]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1525],\n",
      "        [0.1349]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.0076],\n",
      "        [0.0809]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.8028, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.1884],\n",
      "        [0.1854],\n",
      "        [0.3048],\n",
      "        [0.3454],\n",
      "        [0.3041],\n",
      "        [0.2678],\n",
      "        [0.3424],\n",
      "        [0.2279],\n",
      "        [0.1994],\n",
      "        [0.2341],\n",
      "        [0.1765],\n",
      "        [0.2398],\n",
      "        [0.3689],\n",
      "        [0.3382],\n",
      "        [0.2047],\n",
      "        [0.3671],\n",
      "        [0.3127],\n",
      "        [0.3771]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.0999],\n",
      "        [0.0989],\n",
      "        [0.1336],\n",
      "        [0.1314],\n",
      "        [0.1335],\n",
      "        [0.1243],\n",
      "        [0.1420],\n",
      "        [0.1129],\n",
      "        [0.1037],\n",
      "        [0.1148],\n",
      "        [0.0957],\n",
      "        [0.1164],\n",
      "        [0.1472],\n",
      "        [0.1411],\n",
      "        [0.1055],\n",
      "        [0.1450],\n",
      "        [0.1355],\n",
      "        [0.1488]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0063],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0002],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.4012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.3757],\n",
      "        [0.7835]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1485],\n",
      "        [0.1275]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.1124]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.7738, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from small_text.active_learner import PoolBasedActiveLearner\n",
    "\n",
    "from small_text.initialization import random_initialization_balanced\n",
    "from small_text.integrations.transformers import TransformerModelArguments\n",
    "from small_text.integrations.transformers.classifiers.factories import TransformerBasedClassificationFactory\n",
    "from small_text.query_strategies import PredictionEntropy\n",
    "from small_text.integrations.transformers import TransformerModelArguments\n",
    "\n",
    "\n",
    "# simulates an initial labeling to warm-start the active learning process\n",
    "def initialize_active_learner(active_learner, y_train):\n",
    "\n",
    "    indices_initial = random_initialization_balanced(y_train, n_samples=20)\n",
    "    active_learner.initialize_data(indices_initial, y_train[indices_initial])\n",
    "\n",
    "    return indices_initial\n",
    "\n",
    "\n",
    "\n",
    "transformer_model = TransformerModelArguments(transformer_model_name)\n",
    "clf_factory = TransformerBasedClassificationFactory(transformer_model, \n",
    "                                                    num_classes, \n",
    "                                                    kwargs=dict({'device': 'cuda', \n",
    "                                                                 'mini_batch_size': 32,\n",
    "                                                                 'class_weight': 'balanced'\n",
    "                                                                }))\n",
    "query_strategy = PredictionEntropy()\n",
    "\n",
    "active_learner = PoolBasedActiveLearner(clf_factory, query_strategy, train)\n",
    "indices_labeled = initialize_active_learner(active_learner, train.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8888591",
   "metadata": {},
   "source": [
    "### Active Learning Loop\n",
    "\n",
    "The main active learning loop queries the unlabeled pool and thereby decides which documents are labeled next.\n",
    "We then provide the labels for those documents and the active learner retrains the model.\n",
    "After each query, we evaluate the current model against the test set and save the result.\n",
    "\n",
    "\n",
    "Note: This is active learning as it is done in a scientific simulation. In reality, the label feedback would have been given by human annotators, and moreover, we would not be able to measure the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aacd866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.65\n",
      "Test accuracy: 0.49\n",
      "loglikelihood_err: \n",
      "tensor([[0.5977],\n",
      "        [0.5000],\n",
      "        [0.4118],\n",
      "        [0.5569],\n",
      "        [0.5481],\n",
      "        [0.5508],\n",
      "        [0.4272],\n",
      "        [0.5488],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5826],\n",
      "        [0.4492],\n",
      "        [0.4771],\n",
      "        [0.4182],\n",
      "        [0.5000],\n",
      "        [0.6260],\n",
      "        [0.5389],\n",
      "        [0.6515],\n",
      "        [0.6057],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.6473],\n",
      "        [0.5000],\n",
      "        [0.4971],\n",
      "        [0.5863],\n",
      "        [0.3992],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.6320],\n",
      "        [0.7850],\n",
      "        [0.5458]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1546],\n",
      "        [0.1667],\n",
      "        [0.1547],\n",
      "        [0.1599],\n",
      "        [0.1610],\n",
      "        [0.1607],\n",
      "        [0.1571],\n",
      "        [0.1609],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1566],\n",
      "        [0.1603],\n",
      "        [0.1640],\n",
      "        [0.1558],\n",
      "        [0.1667],\n",
      "        [0.1507],\n",
      "        [0.1621],\n",
      "        [0.1472],\n",
      "        [0.1535],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1478],\n",
      "        [0.1667],\n",
      "        [0.1663],\n",
      "        [0.1561],\n",
      "        [0.1527],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1499],\n",
      "        [0.1273],\n",
      "        [0.1613]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0165],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0059],\n",
      "        [0.0043],\n",
      "        [0.0048],\n",
      "        [0.0000],\n",
      "        [0.0044],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0120],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0264],\n",
      "        [0.0028],\n",
      "        [0.0370],\n",
      "        [0.0191],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0352],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0131],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0288],\n",
      "        [0.1134],\n",
      "        [0.0039]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5723]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1579]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0094]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.4139],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5373],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1551],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1623],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0026],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5814]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1568]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0117]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5096]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1656]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0002]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.4961],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1662],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5210],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.4762],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1643],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1639],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0009],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0')\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loglikelihood_err: \n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n",
      "loglikelihood_var: \n",
      "tensor([[0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667],\n",
      "        [0.1667]], device='cuda:0')\n",
      "KL: \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "loss: \n",
      "tensor(0.6667, device='cuda:0')\n",
      "---------------\n",
      "Iteration #0 (40 samples)\n",
      "Train accuracy: 0.80\n",
      "Test accuracy: 0.52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.76.47.4/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb#ch0000017vscode-remote?line=19'>20</a>\u001b[0m results\u001b[39m.\u001b[39mappend(evaluate(active_learner, train[indices_labeled], test))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.76.47.4/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb#ch0000017vscode-remote?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_queries):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.76.47.4/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb#ch0000017vscode-remote?line=23'>24</a>\u001b[0m     \u001b[39m# ...where each iteration consists of labelling 20 samples\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B141.76.47.4/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb#ch0000017vscode-remote?line=24'>25</a>\u001b[0m     indices_queried \u001b[39m=\u001b[39m active_learner\u001b[39m.\u001b[39;49mquery(num_samples\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.76.47.4/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb#ch0000017vscode-remote?line=26'>27</a>\u001b[0m     \u001b[39m# Simulate user interaction here. Replace this for real-world usage.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B141.76.47.4/home/smaghino/small-text/examples/notebooks/01-active-learning-for-text-classification-with-small-text-intro.ipynb#ch0000017vscode-remote?line=27'>28</a>\u001b[0m     y \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39my[indices_queried]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/small_text/active_learner.py:194\u001b[0m, in \u001b[0;36mPoolBasedActiveLearner.query\u001b[0;34m(self, num_samples, representation, query_strategy_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=190'>191</a>\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(size)\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=192'>193</a>\u001b[0m representation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39mif\u001b[39;00m representation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m representation\n\u001b[0;32m--> <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=193'>194</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices_queried \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_strategy\u001b[39m.\u001b[39;49mquery(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clf,\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=194'>195</a>\u001b[0m                                                  representation,\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=195'>196</a>\u001b[0m                                                  indices[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask],\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=196'>197</a>\u001b[0m                                                  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices_labeled,\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=197'>198</a>\u001b[0m                                                  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my,\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=198'>199</a>\u001b[0m                                                  n\u001b[39m=\u001b[39;49mnum_samples,\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=199'>200</a>\u001b[0m                                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mquery_strategy_kwargs)\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/active_learner.py?line=200'>201</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices_queried\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py:76\u001b[0m, in \u001b[0;36mConfidenceBasedQueryStrategy.query\u001b[0;34m(self, clf, dataset, indices_unlabeled, indices_labeled, y, n)\u001b[0m\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=72'>73</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery\u001b[39m(\u001b[39mself\u001b[39m, clf, dataset, indices_unlabeled, indices_labeled, y, n\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=73'>74</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_query_input(indices_unlabeled, n)\n\u001b[0;32m---> <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=75'>76</a>\u001b[0m     confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore(clf, dataset, indices_unlabeled, indices_labeled, y)\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=77'>78</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(indices_unlabeled) \u001b[39m==\u001b[39m n:\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=78'>79</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(indices_unlabeled)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py:108\u001b[0m, in \u001b[0;36mConfidenceBasedQueryStrategy.score\u001b[0;34m(self, clf, dataset, indices_unlabeled, indices_labeled, y)\u001b[0m\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=83'>84</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, clf, dataset, indices_unlabeled, indices_labeled, y):\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=84'>85</a>\u001b[0m     \u001b[39m\"\"\"Assigns a confidence score to each instance.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=85'>86</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=86'>87</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=104'>105</a>\u001b[0m \u001b[39m        subsequent methods do not need to differentiate maximization/minimization.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=105'>106</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=107'>108</a>\u001b[0m     confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_confidence(clf, dataset, indices_unlabeled, indices_labeled, y)\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=108'>109</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscores_ \u001b[39m=\u001b[39m confidence\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=109'>110</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower_is_better:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py:184\u001b[0m, in \u001b[0;36mPredictionEntropy.get_confidence\u001b[0;34m(self, clf, dataset, _indices_unlabeled, _indices_labeled, _y)\u001b[0m\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=182'>183</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_confidence\u001b[39m(\u001b[39mself\u001b[39m, clf, dataset, _indices_unlabeled, _indices_labeled, _y):\n\u001b[0;32m--> <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=183'>184</a>\u001b[0m     proba \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict_proba(dataset)\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/query_strategies/strategies.py?line=184'>185</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: entropy(x), \u001b[39m1\u001b[39m, proba)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/small_text/integrations/transformers/classifiers/classification.py:750\u001b[0m, in \u001b[0;36mTransformerBasedClassification.predict_proba\u001b[0;34m(self, test_set)\u001b[0m\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/integrations/transformers/classifiers/classification.py?line=746'>747</a>\u001b[0m         text, masks \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), masks\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/integrations/transformers/classifiers/classification.py?line=747'>748</a>\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(text, attention_mask\u001b[39m=\u001b[39mmasks)\n\u001b[0;32m--> <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/integrations/transformers/classifiers/classification.py?line=749'>750</a>\u001b[0m         predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m logits_transform(outputs\u001b[39m.\u001b[39;49mlogits)\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/integrations/transformers/classifiers/classification.py?line=750'>751</a>\u001b[0m         \u001b[39mdel\u001b[39;00m text, masks\n\u001b[1;32m    <a href='file:///home/smaghino/.local/lib/python3.8/site-packages/small_text/integrations/transformers/classifiers/classification.py?line=752'>753</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(predictions)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "num_queries = 10\n",
    "\n",
    "\n",
    "def evaluate(active_learner, train, test):\n",
    "    y_pred = active_learner.classifier.predict(train)\n",
    "    y_pred_test = active_learner.classifier.predict(test)\n",
    "    \n",
    "    test_acc = accuracy_score(y_pred_test, test.y)\n",
    "\n",
    "    print('Train accuracy: {:.2f}'.format(accuracy_score(y_pred, train.y)))\n",
    "    print('Test accuracy: {:.2f}'.format(test_acc))\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "\n",
    "results = []\n",
    "results.append(evaluate(active_learner, train[indices_labeled], test))\n",
    "\n",
    "    \n",
    "for i in range(num_queries):\n",
    "    # ...where each iteration consists of labelling 20 samples\n",
    "    indices_queried = active_learner.query(num_samples=20)\n",
    "\n",
    "    # Simulate user interaction here. Replace this for real-world usage.\n",
    "    y = train.y[indices_queried]\n",
    "\n",
    "    # Return the labels for the current query to the active learner.\n",
    "    active_learner.update(y)\n",
    "\n",
    "    indices_labeled = np.concatenate([indices_queried, indices_labeled])\n",
    "    \n",
    "    print('---------------')\n",
    "    print(f'Iteration #{i} ({len(indices_labeled)} samples)')\n",
    "    results.append(evaluate(active_learner, train[indices_labeled], test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb9a63",
   "metadata": {},
   "source": [
    "### Plotting the Results\n",
    "\n",
    "Using the previously saved results we can plot a [learning curve](https://en.wikipedia.org/wiki/Learning_curve_(machine_learning)) to visualize the resulting accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c1d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = plt.axes()\n",
    "\n",
    "data = np.vstack((np.arange(num_queries+1), np.array(results)))\n",
    "sns.lineplot(x=0, y=1, data=data)\n",
    "\n",
    "plt.xlabel('number of queries', labelpad=15)\n",
    "plt.ylabel('test accuracy', labelpad=25)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f82ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
